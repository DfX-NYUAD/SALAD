model_args:
  pretrained_model_name_or_path: "meta-llama/Llama-3.1-8B-Instruct"
  attn_implementation: 'flash_attention_2'
  torch_dtype: bfloat16
tokenizer_args:
  pretrained_model_name_or_path: "meta-llama/Llama-3.1-8B-Instruct"
template_args:
  apply_chat_template: False
#   system_prompt: You are a professional hardware Verilog expert.
#   system_prompt_with_special_tokens: "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n<|eot_id|>"
#   user_start_tag: "<|start_header_id|>user<|end_header_id|>\n\n"
#   user_end_tag: "<|eot_id|>"
#   asst_start_tag: "<|start_header_id|>assistant<|end_header_id|>\n\n"
#   asst_end_tag: "<|eot_id|>"