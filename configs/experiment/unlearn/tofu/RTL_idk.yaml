# @package _global_

defaults:
  - override /model: Llama-3.1-8B-Instruct
  - override /trainer: DPO
  - override /data: unlearn
  - override /data/datasets@data.forget: RTL_QA_forget_idk
  - override /data/datasets@data.retain: RTL_QA_retain
  - override /eval: tofu

model:
  model_args:
    pretrained_model_name_or_path: meta-llama/Llama-3.1-8B-Instruct


forget_split: RTL_QA_forget_idk
holdout_split: RTL_QA_holdout
retain_split: RTL_QA_retain
retain_logs_path: null


eval:
  tofu:
    forget_split: ${forget_split}
    retain_logs_path: ${retain_logs_path}
    overwrite: true
    
# data:
#   anchor: forget
#   forget:
#     TOFU_QA_forget_idk: 
#       args:
#         hf_args:
#           name: ${forget_split}
#   retain:
#     TOFU_QA_retain:
#       args:
#         hf_args:
#           name: ${retain_split}

trainer:
  args:
    warmup_epochs: 1.0 # custom parameter
    learning_rate: 1e-5
    weight_decay: 0.01
    num_train_epochs: 10
    # save_strategy: steps
    # save_steps: 0.5

task_name: ???
